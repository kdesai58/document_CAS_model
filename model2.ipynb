{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIZVUvCvqchS",
    "outputId": "01a0d8eb-44eb-434b-ead0-d3924aaf3682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/anaconda3/lib/python3.12/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DxaeVM3-qchS"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        text = \"\"\n",
    "        for page in range(len(reader.pages)):\n",
    "            text += reader.pages[page].extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error extracting text from PDF: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heJ93oK7qchT",
    "outputId": "1f917f45-4c3b-4463-e2f2-c7fe5108d41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/anaconda3/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in /Users/anaconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: datasets in /Users/anaconda3/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /Users/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /Users/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSTqpfoeqchT",
    "outputId": "0f3abf18-f0a3-45d4-8c9a-82b7ff2c2f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid! Logged in as: khilandesai\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "token = \"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\"\n",
    "\n",
    "try:\n",
    "    user_info = whoami(token)\n",
    "    print(f\"Token is valid! Logged in as: {user_info['name']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Token validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9aOEHJkOqchT"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_huggingface_token' with the token you generated\n",
    "login(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RI-WLdlDqchT"
   },
   "outputs": [],
   "source": [
    "# huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OF3q6EXVqchT",
    "outputId": "08c63b51-5ce9-4b62-8cae-2857f2df61d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.26.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.11.0)\n",
      "Requirement already satisfied: networkx in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WnLW-T_9qchT"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "\n",
    "# accelerator = Accelerator()\n",
    "# Load the tokenizer and model\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"  # Change to the specific LLaMA model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Ensure pad_token_id is set correctly (Llama models may not have a pad_token by default)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id  # Set it to EOS token if it's not available\n",
    "\n",
    "# model = accelerator.prepare(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_aUqSdyuqchT"
   },
   "outputs": [],
   "source": [
    "def classify_text(text, categories):\n",
    "    \"\"\"\n",
    "    Classifies text into one of the given categories using LLaMA.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    The following is a classification task. Classify the given text into one of the following categories:\n",
    "    {\", \".join(categories)}.\n",
    "\n",
    "    Text: {text}\n",
    "\n",
    "    Category:\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, padding=True,truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = inputs.to(device)\n",
    "    model.to(device)  # Move the model to the same device as inputs\n",
    "\n",
    "    # Ensure attention mask is properly set\n",
    "    attention_mask = inputs.get('attention_mask', torch.ones(inputs['input_ids'].shape))\n",
    "\n",
    "    # Run the model to get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=inputs['input_ids'], attention_mask=attention_mask, max_length=100)\n",
    "\n",
    "    # Decode the output and extract the category\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract the category by looking after the 'Category:' part\n",
    "    classification = output_text.split('Category:')[-1].strip()\n",
    "\n",
    "    # Return the predicted category\n",
    "    return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7_ljzxJqchT",
    "outputId": "a587c6b6-4ebf-427e-eec5-34b4ff43b343"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Finance\n",
      "\n",
      "    Text: The US healthcare system is the most\n"
     ]
    }
   ],
   "source": [
    "categories = [\"Technology\", \"Finance\" ,\"Healthcare\", \"Education\", \"Arts\", \"General knowledge\", \"Science\", \"Sports\"]\n",
    "text = \"Artificial intelligence is revolutionizing healthcare by improving diagnostics and treatments.\"\n",
    "\n",
    "predicted_category = classify_text(text, categories)\n",
    "print(f\"Predicted Category: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JgJ-AekYqchT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a classification pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def classify_text(text):\n",
    "    \"\"\"Classify the text using a Hugging Face model.\"\"\"\n",
    "    result = classifier(text[:1024])  # Process the first 512 tokens for simplicity\n",
    "    return result[0][\"label\"], result[0][\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8f2psIZoqchT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"google/flan-t5-small\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Summarize the input text.\"\"\"\n",
    "    return summarizer(text[:2048], max_length=100, min_length=30, do_sample=False)[0][\"summary_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hACtv2AiqchT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /Users/anaconda3/lib/python3.12/site-packages (0.115.5)\n",
      "Requirement already satisfied: sentence-transformers in /Users/anaconda3/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/anaconda3/lib/python3.12/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: uvicorn in /Users/anaconda3/lib/python3.12/site-packages (0.32.1)\n",
      "Requirement already satisfied: nest_asyncio in /Users/anaconda3/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: pyngrok in /Users/anaconda3/lib/python3.12/site-packages (7.2.1)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /Users/anaconda3/lib/python3.12/site-packages (from fastapi) (0.41.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/anaconda3/lib/python3.12/site-packages (from fastapi) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/anaconda3/lib/python3.12/site-packages (from fastapi) (4.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /Users/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/anaconda3/lib/python3.12/site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/anaconda3/lib/python3.12/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/anaconda3/lib/python3.12/site-packages (from pyngrok) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: requests in /Users/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/anaconda3/lib/python3.12/site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: networkx in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi sentence-transformers faiss-cpu uvicorn nest_asyncio pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RqMGIqBSqchT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# FAISS Index\n",
    "dimension = 384  # Embedding size of all-MiniLM-L6-v2\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance metric\n",
    "\n",
    "# Database to store metadata\n",
    "document_db = []\n",
    "\n",
    "def add_document_to_index(doc_id, text):\n",
    "    \"\"\"Generate embeddings and add them to FAISS index.\"\"\"\n",
    "    embedding = embedding_model.encode([text])[0]  # Generate embedding\n",
    "    index.add(np.array([embedding]))  # Add to FAISS index\n",
    "    document_db.append({\"id\": doc_id, \"text\": text})  # Add metadata to DB\n",
    "\n",
    "def search_documents(query, top_k=5):\n",
    "    \"\"\"Perform a similarity search using FAISS.\"\"\"\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    distances, indices = index.search(np.array([query_embedding]), top_k)\n",
    "    results = [document_db[i] for i in indices[0]]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zcZENidRqchU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-multipart in /Users/anaconda3/lib/python3.12/site-packages (0.0.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "q5jie4QFqchU"
   },
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "# @app.get(\"/\")\n",
    "# def read_root():\n",
    "#     return {\"Hello\": \"World\"}\n",
    "\n",
    "# @app.post(\"/upload/\")\n",
    "# async def upload_file():\n",
    "#     return {\"message\": \"File uploaded!\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "o1f8mL45qchU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [11026]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51067 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:51067 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51067 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51067 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51067 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [11026]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import necessary modules\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "UPLOAD_DIR = \"./uploads\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# def extract_text_from_pdf(file_path: str) -> str:\n",
    "#     try:\n",
    "#         reader = PdfReader(file_path)\n",
    "#         text = \"\"\n",
    "#         for page in reader.pages:\n",
    "#             text += page.extract_text()\n",
    "#         return text\n",
    "#     except Exception as e:\n",
    "#         raise ValueError(f\"Error extracting text from PDF: {e}\")\n",
    "\n",
    "@app.post(\"/upload/\")\n",
    "async def upload_document(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        file_location = os.path.join(UPLOAD_DIR, file.filename)\n",
    "        with open(file_location, \"wb\") as f:\n",
    "            f.write(await file.read())\n",
    "        text = extract_text_from_pdf(file_location)\n",
    "        # Summarize, classify, and embed\n",
    "        summary = summarize_text(text)\n",
    "        label, score = classify_text(text)\n",
    "        add_document_to_index(doc_id, text)\n",
    "\n",
    "        # Return results\n",
    "        return {\n",
    "            \"id\": doc_id,\n",
    "            \"filename\": file.filename,\n",
    "            \"extracted_text\": text,\n",
    "            \"summary\": summary,\n",
    "            \"classification\": {\"label\": label, \"score\": score}\n",
    "        }\n",
    "        # return {\"message\": \"File uploaded and text extracted successfully!\", \"extracted_text\": text}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error: {e}\")\n",
    "\n",
    "@app.get(\"/search/\")\n",
    "async def search_document(query: str):\n",
    "    try:\n",
    "        results = search_documents(query)\n",
    "        return {\"results\": results}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error: {e}\")\n",
    "\n",
    "# Run FastAPI in notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# # Optional: Expose your app to the internet using ngrok\n",
    "# public_url = ngrok.connect(8000)\n",
    "# print(f\"Public URL: {public_url}\")\n",
    "\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c308wMsqchU"
   },
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI, UploadFile, File\n",
    "# import uuid\n",
    "# import shutil\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "# @app.get(\"/\")\n",
    "# def read_root():\n",
    "#     return {\"message\": \"Welcome to the FastAPI app!\"}\n",
    "\n",
    "# @app.post(\"/upload/\")\n",
    "# async def upload_document(file: UploadFile = File(...)):\n",
    "#     \"\"\"Upload and process a document.\"\"\"\n",
    "#     doc_id = str(uuid.uuid4())  # Generate unique ID\n",
    "#     file_path = f\"uploads/{doc_id}_{file.filename}\"\n",
    "\n",
    "#     # Save the uploaded file\n",
    "#     with open(file_path, \"wb\") as buffer:\n",
    "#         shutil.copyfileobj(file.file, buffer)\n",
    "\n",
    "#     # Extract text from the document\n",
    "#     text = extract_text_from_pdf(file_path)\n",
    "\n",
    "#     # Summarize, classify, and embed\n",
    "#     summary = summarize_text(text)\n",
    "#     label, score = classify_text(text)\n",
    "#     add_document_to_index(doc_id, text)\n",
    "\n",
    "#     # Return results\n",
    "#     return {\n",
    "#         \"id\": doc_id,\n",
    "#         \"filename\": file.filename,\n",
    "#         \"summary\": summary,\n",
    "#         \"classification\": {\"label\": label, \"score\": score}\n",
    "#     }\n",
    "\n",
    "# @app.get(\"/search/\")\n",
    "# async def search(query: str):\n",
    "#     \"\"\"Search for documents based on a query.\"\"\"\n",
    "#     results = search_documents(query)\n",
    "#     return {\"query\": query, \"results\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mb62GBfCqchU"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9sb-4QdqchU"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Upload a file\n",
    "url = \"http://0.0.0.0:8000/upload/\"\n",
    "files = {\"file\": open(\"/Users/HP 1/Desktop/Project1/document_CAS_model/0000/0000009.pdf\", \"rb\")}\n",
    "response = requests.post(url, files=files)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMnRWYqrqchU"
   },
   "outputs": [],
   "source": [
    "# Search for a term\n",
    "url = \"http://127.0.0.1:8000/search/\"\n",
    "params = {\"query\": \"linear regression\"}\n",
    "response = requests.get(url, params=params)\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
